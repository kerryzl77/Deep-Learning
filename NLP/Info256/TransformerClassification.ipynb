{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "inr4HSeKoZbE"
      },
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/dbamman/anlp24/blob/main/5.classification/HW6_TransformerClassification_TODO.ipynb)\n",
        "\n",
        "**N.B.** Once it's open on Colab, remember to save a copy (by e.g. clicking `Copy to Drive` above).\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ubRzhaCVXYUy"
      },
      "source": [
        "Thie notebook explores using transformers for document classification.  Before starting, change the runtime to GPU: Runtime > Change runtime type > Hardware accelerator: GPU (any GPU is fine).\n",
        "\n",
        "For an intro to models in PyTorch, see [this tutorial](https://pytorch.org/tutorials/beginner/introyt/modelsyt_tutorial.html).\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eQnqbL-NjmiP"
      },
      "source": [
        "Download classification data for training/evaluation."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "dmi6Kkin6p3G"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "X9UUcu7TG6sg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a6f9aa52-97fa-4ad6-cf6b-f94fa11e4a90"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-10-13 03:51:19--  https://raw.githubusercontent.com/dbamman/anlp24/main/data/convote/train.tsv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 4660140 (4.4M) [text/plain]\n",
            "Saving to: ‘train.tsv.1’\n",
            "\n",
            "train.tsv.1         100%[===================>]   4.44M  --.-KB/s    in 0.06s   \n",
            "\n",
            "2024-10-13 03:51:19 (78.0 MB/s) - ‘train.tsv.1’ saved [4660140/4660140]\n",
            "\n",
            "--2024-10-13 03:51:19--  https://raw.githubusercontent.com/dbamman/anlp24/main/data/convote/dev.tsv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.110.133, 185.199.109.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 351382 (343K) [text/plain]\n",
            "Saving to: ‘dev.tsv.1’\n",
            "\n",
            "dev.tsv.1           100%[===================>] 343.15K  --.-KB/s    in 0.03s   \n",
            "\n",
            "2024-10-13 03:51:20 (10.4 MB/s) - ‘dev.tsv.1’ saved [351382/351382]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://raw.githubusercontent.com/dbamman/anlp24/main/data/convote/train.tsv\n",
        "!wget https://raw.githubusercontent.com/dbamman/anlp24/main/data/convote/dev.tsv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "PwsQCWgmHLrP"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "import sys\n",
        "import torch\n",
        "from torch import nn\n",
        "from collections import Counter\n",
        "from nltk import word_tokenize"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "eS2rympQIObz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d0bca064-b4cc-4bb3-a1e1-b792efdc96a8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('punkt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "QDlR2HlLHO7J"
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "l3zDewVZHW23",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fc40157f-74e5-4f4d-9399-0c2f35633196"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "********************************************\n",
            "Running on: cuda\n",
            "********************************************\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# max sequence length\n",
        "max_length=256\n",
        "\n",
        "# limit vocabulary to top N words in training data\n",
        "max_vocab=10000\n",
        "\n",
        "# batch size\n",
        "batch_size=128\n",
        "\n",
        "# size of token representations (which dictates the size of the overall model).\n",
        "d_model=16\n",
        "\n",
        "\n",
        "# number of epochs\n",
        "num_epochs=50\n",
        "\n",
        "print('')\n",
        "print(\"********************************************\")\n",
        "print(\"Running on: {}\".format(device))\n",
        "print(\"********************************************\")\n",
        "print('')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "h5IJ2unzHYzu"
      },
      "outputs": [],
      "source": [
        "# PositionalEncoding class copied from:\n",
        "# https://github.com/pytorch/examples/blob/main/word_language_model/model.py\n",
        "\n",
        "class PositionalEncoding(nn.Module):\n",
        "\n",
        "    def __init__(self, d_model, dropout=0.1):\n",
        "        super(PositionalEncoding, self).__init__()\n",
        "        self.dropout = nn.Dropout(p=dropout)\n",
        "\n",
        "        pe = torch.zeros(max_length, d_model)\n",
        "        position = torch.arange(0, max_length, dtype=torch.float).unsqueeze(1)\n",
        "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
        "        pe[:, 0::2] = torch.sin(position * div_term)\n",
        "        pe[:, 1::2] = torch.cos(position * div_term)\n",
        "        pe = pe.unsqueeze(0)#.transpose(0, 1)\n",
        "        self.register_buffer('pe', pe)\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        x = x + self.pe[:x.size(0), :]\n",
        "        return self.dropout(x)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "pMTmsPDjHast"
      },
      "outputs": [],
      "source": [
        "class TransformerClassifier(torch.nn.Module):\n",
        "\n",
        "    def __init__(self, num_labels, d_model, nhead=2, num_encoder_layers=1, dim_feedforward=256):\n",
        "\n",
        "        super(TransformerClassifier, self).__init__()\n",
        "\n",
        "        self.num_labels=num_labels\n",
        "        self.embedding = nn.Embedding(num_embeddings=max_vocab+2, embedding_dim=d_model)\n",
        "        self.transformer = nn.Transformer(d_model=d_model, nhead=nhead, num_encoder_layers=num_encoder_layers, dim_feedforward=dim_feedforward, batch_first=True)\n",
        "        self.classifier = nn.Linear(d_model, self.num_labels)\n",
        "        self.pos_encoder = PositionalEncoding(d_model)\n",
        "\n",
        "    def forward(self, x, m):\n",
        "        # Convert lists to tensors if necessary\n",
        "        if isinstance(x, list):\n",
        "            x = torch.tensor(x, dtype=torch.long)\n",
        "        if isinstance(m, list):\n",
        "            m = torch.tensor(m, dtype=torch.bool)\n",
        "\n",
        "        # put data on device (e.g., gpu)\n",
        "        x=x.to(device)\n",
        "        m=m.to(device)\n",
        "\n",
        "        # convert input token IDs to word embeddings\n",
        "        embed=self.embedding(x)\n",
        "\n",
        "        # add position encodings to include information about word position within the document\n",
        "        embed = self.pos_encoder(embed)\n",
        "\n",
        "        # get transformer output\n",
        "        h=self.transformer.encoder(embed, src_key_padding_mask=m)\n",
        "\n",
        "        # Represent document as average embedding of transformer output\n",
        "        h=torch.mean(h, dim=1)\n",
        "\n",
        "        # Convert document representation into output label space\n",
        "        logits=self.classifier(h)\n",
        "\n",
        "        return logits\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "TT56POLcHcLM"
      },
      "outputs": [],
      "source": [
        "def create_vocab_and_labels(filename, max_vocab):\n",
        "    # This function creates the word vocabulary (and label ids) from the training data\n",
        "    # The vocab is a mapping between word types and unique word IDs\n",
        "\n",
        "    counts=Counter()\n",
        "    labels={}\n",
        "    with open(filename, encoding=\"utf-8\") as file:\n",
        "        for line in file:\n",
        "            cols=line.rstrip().split(\"\\t\")\n",
        "            lab=cols[0]\n",
        "            text=word_tokenize(cols[1].lower())\n",
        "            for tok in text:\n",
        "                counts[tok]+=1\n",
        "\n",
        "            if lab not in labels:\n",
        "                labels[lab]=len(labels)\n",
        "\n",
        "    vocab={\"[MASK]\":0, \"[UNK]\":1}\n",
        "\n",
        "    for k,v in counts.most_common(max_vocab):\n",
        "        vocab[k]=len(vocab)\n",
        "\n",
        "    return vocab, labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "tB9Vv3TiHdkW"
      },
      "outputs": [],
      "source": [
        "def read_data(filename, vocab, labels, max_length, max_docs=5000):\n",
        "    # Read in data from file, up to the first max_docs documents. For each document\n",
        "    # read up to max_length tokens.\n",
        "\n",
        "    x=[]\n",
        "    y=[]\n",
        "    m=[]\n",
        "\n",
        "    with open(filename, encoding=\"utf-8\") as file:\n",
        "        for idx, line in enumerate(file):\n",
        "            if idx >= max_docs:\n",
        "                break\n",
        "            cols=line.rstrip().split(\"\\t\")\n",
        "            lab=cols[0]\n",
        "            text=word_tokenize(cols[1])\n",
        "            text_ids=[]\n",
        "            for tok in text:\n",
        "                if tok in vocab:\n",
        "                    text_ids.append(vocab[tok])\n",
        "                else:\n",
        "                    text_ids.append(vocab[\"[UNK]\"])\n",
        "\n",
        "            text_ids=text_ids[:max_length]\n",
        "\n",
        "            # PyTorch (and most libraries that deal with matrix operations) expects all inputs to be the same length\n",
        "            # So pad each document with 0s up to max_length\n",
        "            # But keep track of the true number of tokens in the document with the \"mask\" list.\n",
        "\n",
        "            # True tokens have a mask value of 0\n",
        "            mask=[0]*len(text_ids)\n",
        "\n",
        "            for i in range(len(text_ids), max_length):\n",
        "                text_ids.append(vocab[\"[MASK]\"])\n",
        "                # Padded tokens have a mask value of 1\n",
        "                mask.append(1)\n",
        "\n",
        "            x.append(text_ids)\n",
        "            m.append(mask)\n",
        "            y.append(labels[lab])\n",
        "\n",
        "    return x, y, m"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "dglYDfx-HfEt"
      },
      "outputs": [],
      "source": [
        "def get_batches(x, y, m, batch_size):\n",
        "\n",
        "    # Create minibatches from the full dataset\n",
        "\n",
        "    batches_x=[]\n",
        "    batches_y=[]\n",
        "    batches_m=[]\n",
        "    for i in range(0, len(x), batch_size):\n",
        "        xbatch=x[i:i+batch_size]\n",
        "        ybatch=y[i:i+batch_size]\n",
        "        mbatch=m[i:i+batch_size]\n",
        "\n",
        "        batches_x.append(torch.LongTensor(xbatch))\n",
        "        batches_y.append(torch.LongTensor(ybatch))\n",
        "        batches_m.append(torch.BoolTensor(mbatch))\n",
        "\n",
        "    return batches_x, batches_y, batches_m"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "_g5m_NjzHgsW"
      },
      "outputs": [],
      "source": [
        "def evaluate(model, all_x, all_y, all_m):\n",
        "\n",
        "    # Calculate accuracy\n",
        "\n",
        "    model.eval()\n",
        "    corr = 0.\n",
        "    total = 0.\n",
        "    with torch.no_grad():\n",
        "        for x, y, m in zip(all_x, all_y, all_m):\n",
        "            y_preds=model.forward(x, m)\n",
        "            for idx, y_pred in enumerate(y_preds):\n",
        "                prediction=torch.argmax(y_pred)\n",
        "                if prediction == y[idx]:\n",
        "                    corr += 1.\n",
        "                total+=1\n",
        "    return corr/total"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "eLjdIDl4HiDE"
      },
      "outputs": [],
      "source": [
        "def train(model, model_filename, train_batches_x, train_batches_y, train_batches_m, dev_batches_x, dev_batches_y, dev_batches_m):\n",
        "\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "    cross_entropy=nn.CrossEntropyLoss()\n",
        "\n",
        "    # Keep track of the epoch that has the best dev accuracy\n",
        "    best_dev_acc=0.\n",
        "    best_dev_epoch=None\n",
        "\n",
        "    # How many epochs with no changes before we quit\n",
        "    patience=10\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "\n",
        "        model.train()\n",
        "\n",
        "        for x, y, m in zip(train_batches_x, train_batches_y, train_batches_m):\n",
        "            # Get predictions for batch x (with mask values m)\n",
        "            y_pred=model.forward(x, m)\n",
        "            y=y.to(device)\n",
        "\n",
        "            # Calculate loss as cross-entropy with true labels\n",
        "            loss = cross_entropy(y_pred.view(-1, model.num_labels), y.view(-1))\n",
        "\n",
        "            # Set all gradients to zero\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # Calculate gradients from current loss\n",
        "            loss.backward()\n",
        "\n",
        "            # Update parameters\n",
        "            optimizer.step()\n",
        "\n",
        "        dev_accuracy=evaluate(model, dev_batches_x, dev_batches_y, dev_batches_m)\n",
        "\n",
        "        # we're going to save the model that performs the best on *dev* data\n",
        "        if dev_accuracy > best_dev_acc:\n",
        "            torch.save(model.state_dict(), model_filename)\n",
        "            print(\"%.3f is better than %.3f, saving model ...\" % (dev_accuracy, best_dev_acc))\n",
        "            best_dev_acc = dev_accuracy\n",
        "            best_dev_epoch=epoch\n",
        "\n",
        "        if epoch % 1 == 0:\n",
        "            print(\"Epoch %s, dev accuracy: %.3f\" % (epoch, dev_accuracy))\n",
        "\n",
        "        if epoch-best_dev_epoch > patience:\n",
        "          print(\"%s > patience (%s), stopping...\" % (epoch-best_dev_epoch, patience))\n",
        "          break\n",
        "\n",
        "    model.load_state_dict(torch.load(model_filename))\n",
        "    print(\"\\nBest Performing Model achieves dev accuracy of : %.3f\" % (best_dev_acc))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "_nkNh6f8HkL2"
      },
      "outputs": [],
      "source": [
        "vocab, labels=create_vocab_and_labels(\"train.tsv\", max_vocab)\n",
        "train_x, train_y, train_m=read_data(\"train.tsv\", vocab, labels, max_length=max_length)\n",
        "dev_x, dev_y, dev_m=read_data(\"dev.tsv\", vocab, labels, max_length=max_length)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "0vtxV6jpHrAV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "592078de-30af-4615-8d76-efd3c135b22c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/transformer.py:409: UserWarning: The PyTorch API of nested tensors is in prototype stage and will change in the near future. (Triggered internally at ../aten/src/ATen/NestedTensorImpl.cpp:178.)\n",
            "  output = torch._nested_tensor_from_mask(output, src_key_padding_mask.logical_not(), mask_check=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.510 is better than 0.000, saving model ...\n",
            "Epoch 0, dev accuracy: 0.510\n",
            "Epoch 1, dev accuracy: 0.498\n",
            "0.518 is better than 0.510, saving model ...\n",
            "Epoch 2, dev accuracy: 0.518\n",
            "0.521 is better than 0.518, saving model ...\n",
            "Epoch 3, dev accuracy: 0.521\n",
            "0.580 is better than 0.521, saving model ...\n",
            "Epoch 4, dev accuracy: 0.580\n",
            "0.607 is better than 0.580, saving model ...\n",
            "Epoch 5, dev accuracy: 0.607\n",
            "Epoch 6, dev accuracy: 0.553\n",
            "Epoch 7, dev accuracy: 0.588\n",
            "0.642 is better than 0.607, saving model ...\n",
            "Epoch 8, dev accuracy: 0.642\n",
            "Epoch 9, dev accuracy: 0.630\n",
            "Epoch 10, dev accuracy: 0.626\n",
            "0.658 is better than 0.642, saving model ...\n",
            "Epoch 11, dev accuracy: 0.658\n",
            "Epoch 12, dev accuracy: 0.642\n",
            "Epoch 13, dev accuracy: 0.638\n",
            "Epoch 14, dev accuracy: 0.626\n",
            "Epoch 15, dev accuracy: 0.630\n",
            "Epoch 16, dev accuracy: 0.603\n",
            "Epoch 17, dev accuracy: 0.591\n",
            "Epoch 18, dev accuracy: 0.580\n",
            "Epoch 19, dev accuracy: 0.630\n",
            "Epoch 20, dev accuracy: 0.603\n",
            "Epoch 21, dev accuracy: 0.623\n",
            "Epoch 22, dev accuracy: 0.611\n",
            "11 > patience (10), stopping...\n",
            "\n",
            "Best Performing Model achieves dev accuracy of : 0.658\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-12-4830a4bf0820>:50: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  model.load_state_dict(torch.load(model_filename))\n"
          ]
        }
      ],
      "source": [
        "classifier=TransformerClassifier(num_labels=len(labels), d_model=100, dim_feedforward=1024)\n",
        "classifier=classifier.to(device)\n",
        "\n",
        "train_x_batch, train_y_match, train_m_match=get_batches(train_x, train_y, train_m, batch_size=batch_size)\n",
        "dev_x_batch, dev_y_match, dev_m_match=get_batches(dev_x, dev_y, dev_m, batch_size=batch_size)\n",
        "\n",
        "train(classifier, \"test.model\", train_x_batch, train_y_match, train_m_match, dev_x_batch, dev_y_match, dev_m_match)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R3dn2o1KKdz_"
      },
      "source": [
        "**Q1**. Play around with this transformer as implemented and experiment with how performance on the dev data changes as a function of `d_model`, `num_encoder_layers`, `nhead`, etc.).  Describe your experiments and report dev accuracy on them below."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Result\n",
        "\n",
        "1. **d_model (Dimensionality of Token Embeddings)**: Dimensionality of token embeddings with higher value capture more complex structure but also increases computation cost and risk of overfitting.\n",
        "  - Increasing d_model from 16 to 64 did not consistently improve accuracy in this case. For example, the model with **d_model=16, num_encoder_layers=1, and nhead=2** achieved the highest accuracy (0.700), while models with d_model=64 had lower accuracy.\n",
        "2. **num_encoder_layers (Number of Transformer Encoder Layers)**: The depth of the transformer model. Again a larger number increase model complexity but could lead to overfitting.\n",
        "  - increasing the number of encoder layers from 1 to 2 did not consistently improve accuracy\n",
        "3. **nhead (Number of Attention Heads)**: Number of attention heads allows the model to focus on different parts of the input sequence in parallel. A higher number increase complexity at the risk of overfitting.\n",
        "  - Increasing the number of attention heads lead to worse performance, particularly in more complex models\n",
        "\n",
        "The highest-performing model (**d_model=16, num_encoder_layers=1, nhead=2, accuracy=0.700**) was one of the simpler configurations. This suggests that the more complex models might have suffered from under-optimization due to:\n",
        "\n",
        "1. Early stopping after 10 epochs lead to oscillation.\n",
        "2. The learning rate or other hyperparameters may not have been tuned well, leading to slower convergence."
      ],
      "metadata": {
        "id": "qgYsxnt5mYsz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import itertools\n",
        "import torch.optim as optim\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "KKWgBNtHmLIf"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define hyperparameters grid search\n",
        "d_model_values = [16, 64]\n",
        "num_encoder_layers_values = [1, 2]\n",
        "nhead_values = [2, 4]"
      ],
      "metadata": {
        "id": "jXXSjDtMpKb4"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results = []\n",
        "train_x_batch, train_y_match, train_m_match = get_batches(train_x, train_y, train_m, batch_size=batch_size)\n",
        "dev_x_batch, dev_y_match, dev_m_match = get_batches(dev_x, dev_y, dev_m, batch_size=batch_size)\n",
        "\n",
        "for d_model, num_encoder_layers, nhead in itertools.product(d_model_values, num_encoder_layers_values, nhead_values):\n",
        "    print(f\"\\nTraining model with d_model={d_model}, num_encoder_layers={num_encoder_layers}, nhead={nhead}\")\n",
        "    classifier = TransformerClassifier(\n",
        "        num_labels=len(labels),\n",
        "        d_model=d_model,\n",
        "        nhead=nhead,\n",
        "        num_encoder_layers=num_encoder_layers,\n",
        "        dim_feedforward=1024\n",
        "    )\n",
        "    classifier = classifier.to(device)\n",
        "\n",
        "    model_filename = f\"model_d{d_model}_l{num_encoder_layers}_h{nhead}.pt\"\n",
        "\n",
        "    train(\n",
        "        classifier,\n",
        "        model_filename,\n",
        "        train_x_batch, train_y_match, train_m_match,\n",
        "        dev_x_batch, dev_y_match, dev_m_match\n",
        "    )\n",
        "\n",
        "    # Load the trained model and evaluate it\n",
        "    loaded_model = TransformerClassifier(\n",
        "        num_labels=len(labels),\n",
        "        d_model=d_model,\n",
        "        nhead=nhead,\n",
        "        num_encoder_layers=num_encoder_layers,\n",
        "        dim_feedforward=1024\n",
        "    )\n",
        "    loaded_model.load_state_dict(torch.load(model_filename))\n",
        "    loaded_model = loaded_model.to(device)\n",
        "\n",
        "    dev_accuracy = evaluate(loaded_model, dev_x_batch, dev_y_match, dev_m_match)\n",
        "    print(f\"Loaded model dev accuracy: {dev_accuracy:.3f}\")\n",
        "\n",
        "    results.append((d_model, num_encoder_layers, nhead, dev_accuracy))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F6hS60sgl7TV",
        "outputId": "8227737b-e984-40ee-fcc8-338f87ecff4d"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training model with d_model=16, num_encoder_layers=1, nhead=2\n",
            "0.494 is better than 0.000, saving model ...\n",
            "Epoch 0, dev accuracy: 0.494\n",
            "Epoch 1, dev accuracy: 0.494\n",
            "0.529 is better than 0.494, saving model ...\n",
            "Epoch 2, dev accuracy: 0.529\n",
            "0.576 is better than 0.529, saving model ...\n",
            "Epoch 3, dev accuracy: 0.576\n",
            "Epoch 4, dev accuracy: 0.549\n",
            "Epoch 5, dev accuracy: 0.518\n",
            "Epoch 6, dev accuracy: 0.518\n",
            "Epoch 7, dev accuracy: 0.510\n",
            "Epoch 8, dev accuracy: 0.533\n",
            "Epoch 9, dev accuracy: 0.556\n",
            "Epoch 10, dev accuracy: 0.556\n",
            "Epoch 11, dev accuracy: 0.576\n",
            "0.580 is better than 0.576, saving model ...\n",
            "Epoch 12, dev accuracy: 0.580\n",
            "0.595 is better than 0.580, saving model ...\n",
            "Epoch 13, dev accuracy: 0.595\n",
            "0.607 is better than 0.595, saving model ...\n",
            "Epoch 14, dev accuracy: 0.607\n",
            "0.615 is better than 0.607, saving model ...\n",
            "Epoch 15, dev accuracy: 0.615\n",
            "Epoch 16, dev accuracy: 0.611\n",
            "0.630 is better than 0.615, saving model ...\n",
            "Epoch 17, dev accuracy: 0.630\n",
            "0.646 is better than 0.630, saving model ...\n",
            "Epoch 18, dev accuracy: 0.646\n",
            "0.681 is better than 0.646, saving model ...\n",
            "Epoch 19, dev accuracy: 0.681\n",
            "0.693 is better than 0.681, saving model ...\n",
            "Epoch 20, dev accuracy: 0.693\n",
            "Epoch 21, dev accuracy: 0.685\n",
            "0.700 is better than 0.693, saving model ...\n",
            "Epoch 22, dev accuracy: 0.700\n",
            "Epoch 23, dev accuracy: 0.685\n",
            "Epoch 24, dev accuracy: 0.669\n",
            "Epoch 25, dev accuracy: 0.681\n",
            "Epoch 26, dev accuracy: 0.677\n",
            "Epoch 27, dev accuracy: 0.669\n",
            "Epoch 28, dev accuracy: 0.658\n",
            "Epoch 29, dev accuracy: 0.661\n",
            "Epoch 30, dev accuracy: 0.661\n",
            "Epoch 31, dev accuracy: 0.638\n",
            "Epoch 32, dev accuracy: 0.661\n",
            "Epoch 33, dev accuracy: 0.654\n",
            "11 > patience (10), stopping...\n",
            "\n",
            "Best Performing Model achieves dev accuracy of : 0.700\n",
            "Loaded model dev accuracy: 0.700\n",
            "\n",
            "Training model with d_model=16, num_encoder_layers=1, nhead=4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-12-4830a4bf0820>:50: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  model.load_state_dict(torch.load(model_filename))\n",
            "<ipython-input-17-42507fac7c56>:33: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  loaded_model.load_state_dict(torch.load(model_filename))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.494 is better than 0.000, saving model ...\n",
            "Epoch 0, dev accuracy: 0.494\n",
            "Epoch 1, dev accuracy: 0.490\n",
            "Epoch 2, dev accuracy: 0.490\n",
            "0.514 is better than 0.494, saving model ...\n",
            "Epoch 3, dev accuracy: 0.514\n",
            "0.521 is better than 0.514, saving model ...\n",
            "Epoch 4, dev accuracy: 0.521\n",
            "Epoch 5, dev accuracy: 0.510\n",
            "Epoch 6, dev accuracy: 0.494\n",
            "Epoch 7, dev accuracy: 0.510\n",
            "Epoch 8, dev accuracy: 0.514\n",
            "Epoch 9, dev accuracy: 0.521\n",
            "0.525 is better than 0.521, saving model ...\n",
            "Epoch 10, dev accuracy: 0.525\n",
            "0.529 is better than 0.525, saving model ...\n",
            "Epoch 11, dev accuracy: 0.529\n",
            "0.533 is better than 0.529, saving model ...\n",
            "Epoch 12, dev accuracy: 0.533\n",
            "Epoch 13, dev accuracy: 0.525\n",
            "Epoch 14, dev accuracy: 0.529\n",
            "Epoch 15, dev accuracy: 0.521\n",
            "0.545 is better than 0.533, saving model ...\n",
            "Epoch 16, dev accuracy: 0.545\n",
            "0.553 is better than 0.545, saving model ...\n",
            "Epoch 17, dev accuracy: 0.553\n",
            "Epoch 18, dev accuracy: 0.549\n",
            "0.560 is better than 0.553, saving model ...\n",
            "Epoch 19, dev accuracy: 0.560\n",
            "Epoch 20, dev accuracy: 0.556\n",
            "Epoch 21, dev accuracy: 0.556\n",
            "Epoch 22, dev accuracy: 0.553\n",
            "Epoch 23, dev accuracy: 0.553\n",
            "Epoch 24, dev accuracy: 0.556\n",
            "0.568 is better than 0.560, saving model ...\n",
            "Epoch 25, dev accuracy: 0.568\n",
            "Epoch 26, dev accuracy: 0.556\n",
            "Epoch 27, dev accuracy: 0.564\n",
            "0.572 is better than 0.568, saving model ...\n",
            "Epoch 28, dev accuracy: 0.572\n",
            "0.576 is better than 0.572, saving model ...\n",
            "Epoch 29, dev accuracy: 0.576\n",
            "Epoch 30, dev accuracy: 0.568\n",
            "Epoch 31, dev accuracy: 0.553\n",
            "Epoch 32, dev accuracy: 0.560\n",
            "Epoch 33, dev accuracy: 0.556\n",
            "Epoch 34, dev accuracy: 0.564\n",
            "Epoch 35, dev accuracy: 0.564\n",
            "Epoch 36, dev accuracy: 0.568\n",
            "Epoch 37, dev accuracy: 0.560\n",
            "Epoch 38, dev accuracy: 0.560\n",
            "Epoch 39, dev accuracy: 0.576\n",
            "0.580 is better than 0.576, saving model ...\n",
            "Epoch 40, dev accuracy: 0.580\n",
            "Epoch 41, dev accuracy: 0.564\n",
            "0.584 is better than 0.580, saving model ...\n",
            "Epoch 42, dev accuracy: 0.584\n",
            "Epoch 43, dev accuracy: 0.576\n",
            "Epoch 44, dev accuracy: 0.572\n",
            "Epoch 45, dev accuracy: 0.568\n",
            "Epoch 46, dev accuracy: 0.568\n",
            "Epoch 47, dev accuracy: 0.572\n",
            "Epoch 48, dev accuracy: 0.568\n",
            "Epoch 49, dev accuracy: 0.576\n",
            "\n",
            "Best Performing Model achieves dev accuracy of : 0.584\n",
            "Loaded model dev accuracy: 0.584\n",
            "\n",
            "Training model with d_model=16, num_encoder_layers=2, nhead=2\n",
            "0.494 is better than 0.000, saving model ...\n",
            "Epoch 0, dev accuracy: 0.494\n",
            "Epoch 1, dev accuracy: 0.486\n",
            "0.498 is better than 0.494, saving model ...\n",
            "Epoch 2, dev accuracy: 0.498\n",
            "Epoch 3, dev accuracy: 0.486\n",
            "Epoch 4, dev accuracy: 0.482\n",
            "Epoch 5, dev accuracy: 0.494\n",
            "Epoch 6, dev accuracy: 0.494\n",
            "Epoch 7, dev accuracy: 0.498\n",
            "0.510 is better than 0.498, saving model ...\n",
            "Epoch 8, dev accuracy: 0.510\n",
            "0.525 is better than 0.510, saving model ...\n",
            "Epoch 9, dev accuracy: 0.525\n",
            "0.537 is better than 0.525, saving model ...\n",
            "Epoch 10, dev accuracy: 0.537\n",
            "0.560 is better than 0.537, saving model ...\n",
            "Epoch 11, dev accuracy: 0.560\n",
            "Epoch 12, dev accuracy: 0.560\n",
            "0.607 is better than 0.560, saving model ...\n",
            "Epoch 13, dev accuracy: 0.607\n",
            "Epoch 14, dev accuracy: 0.568\n",
            "0.646 is better than 0.607, saving model ...\n",
            "Epoch 15, dev accuracy: 0.646\n",
            "Epoch 16, dev accuracy: 0.623\n",
            "Epoch 17, dev accuracy: 0.634\n",
            "Epoch 18, dev accuracy: 0.615\n",
            "Epoch 19, dev accuracy: 0.615\n",
            "Epoch 20, dev accuracy: 0.619\n",
            "Epoch 21, dev accuracy: 0.630\n",
            "Epoch 22, dev accuracy: 0.646\n",
            "Epoch 23, dev accuracy: 0.630\n",
            "0.650 is better than 0.646, saving model ...\n",
            "Epoch 24, dev accuracy: 0.650\n",
            "Epoch 25, dev accuracy: 0.623\n",
            "Epoch 26, dev accuracy: 0.615\n",
            "Epoch 27, dev accuracy: 0.619\n",
            "Epoch 28, dev accuracy: 0.638\n",
            "Epoch 29, dev accuracy: 0.642\n",
            "Epoch 30, dev accuracy: 0.634\n",
            "Epoch 31, dev accuracy: 0.626\n",
            "Epoch 32, dev accuracy: 0.623\n",
            "Epoch 33, dev accuracy: 0.646\n",
            "0.661 is better than 0.650, saving model ...\n",
            "Epoch 34, dev accuracy: 0.661\n",
            "Epoch 35, dev accuracy: 0.626\n",
            "Epoch 36, dev accuracy: 0.630\n",
            "Epoch 37, dev accuracy: 0.642\n",
            "Epoch 38, dev accuracy: 0.630\n",
            "Epoch 39, dev accuracy: 0.634\n",
            "Epoch 40, dev accuracy: 0.626\n",
            "Epoch 41, dev accuracy: 0.646\n",
            "Epoch 42, dev accuracy: 0.650\n",
            "Epoch 43, dev accuracy: 0.646\n",
            "Epoch 44, dev accuracy: 0.630\n",
            "Epoch 45, dev accuracy: 0.638\n",
            "11 > patience (10), stopping...\n",
            "\n",
            "Best Performing Model achieves dev accuracy of : 0.661\n",
            "Loaded model dev accuracy: 0.661\n",
            "\n",
            "Training model with d_model=16, num_encoder_layers=2, nhead=4\n",
            "0.510 is better than 0.000, saving model ...\n",
            "Epoch 0, dev accuracy: 0.510\n",
            "Epoch 1, dev accuracy: 0.510\n",
            "Epoch 2, dev accuracy: 0.510\n",
            "0.518 is better than 0.510, saving model ...\n",
            "Epoch 3, dev accuracy: 0.518\n",
            "Epoch 4, dev accuracy: 0.486\n",
            "Epoch 5, dev accuracy: 0.510\n",
            "Epoch 6, dev accuracy: 0.510\n",
            "0.553 is better than 0.518, saving model ...\n",
            "Epoch 7, dev accuracy: 0.553\n",
            "Epoch 8, dev accuracy: 0.553\n",
            "0.560 is better than 0.553, saving model ...\n",
            "Epoch 9, dev accuracy: 0.560\n",
            "0.564 is better than 0.560, saving model ...\n",
            "Epoch 10, dev accuracy: 0.564\n",
            "0.568 is better than 0.564, saving model ...\n",
            "Epoch 11, dev accuracy: 0.568\n",
            "0.572 is better than 0.568, saving model ...\n",
            "Epoch 12, dev accuracy: 0.572\n",
            "0.576 is better than 0.572, saving model ...\n",
            "Epoch 13, dev accuracy: 0.576\n",
            "0.588 is better than 0.576, saving model ...\n",
            "Epoch 14, dev accuracy: 0.588\n",
            "Epoch 15, dev accuracy: 0.588\n",
            "Epoch 16, dev accuracy: 0.580\n",
            "Epoch 17, dev accuracy: 0.568\n",
            "Epoch 18, dev accuracy: 0.568\n",
            "Epoch 19, dev accuracy: 0.560\n",
            "Epoch 20, dev accuracy: 0.564\n",
            "Epoch 21, dev accuracy: 0.588\n",
            "Epoch 22, dev accuracy: 0.560\n",
            "Epoch 23, dev accuracy: 0.576\n",
            "Epoch 24, dev accuracy: 0.556\n",
            "0.591 is better than 0.588, saving model ...\n",
            "Epoch 25, dev accuracy: 0.591\n",
            "Epoch 26, dev accuracy: 0.588\n",
            "0.595 is better than 0.591, saving model ...\n",
            "Epoch 27, dev accuracy: 0.595\n",
            "Epoch 28, dev accuracy: 0.572\n",
            "Epoch 29, dev accuracy: 0.572\n",
            "Epoch 30, dev accuracy: 0.576\n",
            "Epoch 31, dev accuracy: 0.572\n",
            "Epoch 32, dev accuracy: 0.580\n",
            "Epoch 33, dev accuracy: 0.576\n",
            "Epoch 34, dev accuracy: 0.568\n",
            "Epoch 35, dev accuracy: 0.584\n",
            "Epoch 36, dev accuracy: 0.588\n",
            "0.603 is better than 0.595, saving model ...\n",
            "Epoch 37, dev accuracy: 0.603\n",
            "Epoch 38, dev accuracy: 0.603\n",
            "0.607 is better than 0.603, saving model ...\n",
            "Epoch 39, dev accuracy: 0.607\n",
            "Epoch 40, dev accuracy: 0.599\n",
            "Epoch 41, dev accuracy: 0.588\n",
            "Epoch 42, dev accuracy: 0.607\n",
            "Epoch 43, dev accuracy: 0.607\n",
            "0.619 is better than 0.607, saving model ...\n",
            "Epoch 44, dev accuracy: 0.619\n",
            "Epoch 45, dev accuracy: 0.599\n",
            "Epoch 46, dev accuracy: 0.611\n",
            "Epoch 47, dev accuracy: 0.619\n",
            "Epoch 48, dev accuracy: 0.619\n",
            "Epoch 49, dev accuracy: 0.603\n",
            "\n",
            "Best Performing Model achieves dev accuracy of : 0.619\n",
            "Loaded model dev accuracy: 0.619\n",
            "\n",
            "Training model with d_model=64, num_encoder_layers=1, nhead=2\n",
            "0.514 is better than 0.000, saving model ...\n",
            "Epoch 0, dev accuracy: 0.514\n",
            "0.521 is better than 0.514, saving model ...\n",
            "Epoch 1, dev accuracy: 0.521\n",
            "0.525 is better than 0.521, saving model ...\n",
            "Epoch 2, dev accuracy: 0.525\n",
            "0.533 is better than 0.525, saving model ...\n",
            "Epoch 3, dev accuracy: 0.533\n",
            "Epoch 4, dev accuracy: 0.533\n",
            "0.576 is better than 0.533, saving model ...\n",
            "Epoch 5, dev accuracy: 0.576\n",
            "Epoch 6, dev accuracy: 0.553\n",
            "Epoch 7, dev accuracy: 0.556\n",
            "Epoch 8, dev accuracy: 0.564\n",
            "0.584 is better than 0.576, saving model ...\n",
            "Epoch 9, dev accuracy: 0.584\n",
            "Epoch 10, dev accuracy: 0.576\n",
            "0.595 is better than 0.584, saving model ...\n",
            "Epoch 11, dev accuracy: 0.595\n",
            "Epoch 12, dev accuracy: 0.584\n",
            "Epoch 13, dev accuracy: 0.591\n",
            "Epoch 14, dev accuracy: 0.588\n",
            "Epoch 15, dev accuracy: 0.588\n",
            "Epoch 16, dev accuracy: 0.588\n",
            "Epoch 17, dev accuracy: 0.572\n",
            "Epoch 18, dev accuracy: 0.591\n",
            "Epoch 19, dev accuracy: 0.584\n",
            "Epoch 20, dev accuracy: 0.591\n",
            "0.599 is better than 0.595, saving model ...\n",
            "Epoch 21, dev accuracy: 0.599\n",
            "0.603 is better than 0.599, saving model ...\n",
            "Epoch 22, dev accuracy: 0.603\n",
            "Epoch 23, dev accuracy: 0.572\n",
            "Epoch 24, dev accuracy: 0.595\n",
            "Epoch 25, dev accuracy: 0.595\n",
            "0.607 is better than 0.603, saving model ...\n",
            "Epoch 26, dev accuracy: 0.607\n",
            "Epoch 27, dev accuracy: 0.599\n",
            "Epoch 28, dev accuracy: 0.603\n",
            "Epoch 29, dev accuracy: 0.595\n",
            "Epoch 30, dev accuracy: 0.599\n",
            "0.619 is better than 0.607, saving model ...\n",
            "Epoch 31, dev accuracy: 0.619\n",
            "Epoch 32, dev accuracy: 0.611\n",
            "Epoch 33, dev accuracy: 0.607\n",
            "Epoch 34, dev accuracy: 0.588\n",
            "Epoch 35, dev accuracy: 0.599\n",
            "0.638 is better than 0.619, saving model ...\n",
            "Epoch 36, dev accuracy: 0.638\n",
            "0.646 is better than 0.638, saving model ...\n",
            "Epoch 37, dev accuracy: 0.646\n",
            "Epoch 38, dev accuracy: 0.642\n",
            "0.650 is better than 0.646, saving model ...\n",
            "Epoch 39, dev accuracy: 0.650\n",
            "Epoch 40, dev accuracy: 0.650\n",
            "0.654 is better than 0.650, saving model ...\n",
            "Epoch 41, dev accuracy: 0.654\n",
            "Epoch 42, dev accuracy: 0.654\n",
            "Epoch 43, dev accuracy: 0.638\n",
            "Epoch 44, dev accuracy: 0.650\n",
            "Epoch 45, dev accuracy: 0.650\n",
            "Epoch 46, dev accuracy: 0.650\n",
            "Epoch 47, dev accuracy: 0.650\n",
            "Epoch 48, dev accuracy: 0.646\n",
            "Epoch 49, dev accuracy: 0.646\n",
            "\n",
            "Best Performing Model achieves dev accuracy of : 0.654\n",
            "Loaded model dev accuracy: 0.654\n",
            "\n",
            "Training model with d_model=64, num_encoder_layers=1, nhead=4\n",
            "0.510 is better than 0.000, saving model ...\n",
            "Epoch 0, dev accuracy: 0.510\n",
            "0.514 is better than 0.510, saving model ...\n",
            "Epoch 1, dev accuracy: 0.514\n",
            "0.525 is better than 0.514, saving model ...\n",
            "Epoch 2, dev accuracy: 0.525\n",
            "0.537 is better than 0.525, saving model ...\n",
            "Epoch 3, dev accuracy: 0.537\n",
            "0.591 is better than 0.537, saving model ...\n",
            "Epoch 4, dev accuracy: 0.591\n",
            "Epoch 5, dev accuracy: 0.580\n",
            "Epoch 6, dev accuracy: 0.572\n",
            "Epoch 7, dev accuracy: 0.584\n",
            "Epoch 8, dev accuracy: 0.584\n",
            "0.599 is better than 0.591, saving model ...\n",
            "Epoch 9, dev accuracy: 0.599\n",
            "0.619 is better than 0.599, saving model ...\n",
            "Epoch 10, dev accuracy: 0.619\n",
            "0.630 is better than 0.619, saving model ...\n",
            "Epoch 11, dev accuracy: 0.630\n",
            "Epoch 12, dev accuracy: 0.615\n",
            "0.634 is better than 0.630, saving model ...\n",
            "Epoch 13, dev accuracy: 0.634\n",
            "Epoch 14, dev accuracy: 0.630\n",
            "Epoch 15, dev accuracy: 0.634\n",
            "0.654 is better than 0.634, saving model ...\n",
            "Epoch 16, dev accuracy: 0.654\n",
            "0.658 is better than 0.654, saving model ...\n",
            "Epoch 17, dev accuracy: 0.658\n",
            "Epoch 18, dev accuracy: 0.615\n",
            "Epoch 19, dev accuracy: 0.626\n",
            "Epoch 20, dev accuracy: 0.626\n",
            "Epoch 21, dev accuracy: 0.584\n",
            "Epoch 22, dev accuracy: 0.626\n",
            "Epoch 23, dev accuracy: 0.615\n",
            "Epoch 24, dev accuracy: 0.619\n",
            "Epoch 25, dev accuracy: 0.615\n",
            "Epoch 26, dev accuracy: 0.607\n",
            "Epoch 27, dev accuracy: 0.619\n",
            "Epoch 28, dev accuracy: 0.619\n",
            "11 > patience (10), stopping...\n",
            "\n",
            "Best Performing Model achieves dev accuracy of : 0.658\n",
            "Loaded model dev accuracy: 0.658\n",
            "\n",
            "Training model with d_model=64, num_encoder_layers=2, nhead=2\n",
            "0.494 is better than 0.000, saving model ...\n",
            "Epoch 0, dev accuracy: 0.494\n",
            "Epoch 1, dev accuracy: 0.494\n",
            "Epoch 2, dev accuracy: 0.494\n",
            "0.537 is better than 0.494, saving model ...\n",
            "Epoch 3, dev accuracy: 0.537\n",
            "Epoch 4, dev accuracy: 0.533\n",
            "0.588 is better than 0.537, saving model ...\n",
            "Epoch 5, dev accuracy: 0.588\n",
            "0.591 is better than 0.588, saving model ...\n",
            "Epoch 6, dev accuracy: 0.591\n",
            "Epoch 7, dev accuracy: 0.568\n",
            "Epoch 8, dev accuracy: 0.591\n",
            "Epoch 9, dev accuracy: 0.591\n",
            "0.595 is better than 0.591, saving model ...\n",
            "Epoch 10, dev accuracy: 0.595\n",
            "0.599 is better than 0.595, saving model ...\n",
            "Epoch 11, dev accuracy: 0.599\n",
            "0.611 is better than 0.599, saving model ...\n",
            "Epoch 12, dev accuracy: 0.611\n",
            "Epoch 13, dev accuracy: 0.607\n",
            "Epoch 14, dev accuracy: 0.588\n",
            "Epoch 15, dev accuracy: 0.599\n",
            "0.623 is better than 0.611, saving model ...\n",
            "Epoch 16, dev accuracy: 0.623\n",
            "Epoch 17, dev accuracy: 0.611\n",
            "Epoch 18, dev accuracy: 0.576\n",
            "0.638 is better than 0.623, saving model ...\n",
            "Epoch 19, dev accuracy: 0.638\n",
            "0.650 is better than 0.638, saving model ...\n",
            "Epoch 20, dev accuracy: 0.650\n",
            "Epoch 21, dev accuracy: 0.607\n",
            "Epoch 22, dev accuracy: 0.630\n",
            "Epoch 23, dev accuracy: 0.595\n",
            "Epoch 24, dev accuracy: 0.615\n",
            "Epoch 25, dev accuracy: 0.611\n",
            "Epoch 26, dev accuracy: 0.619\n",
            "Epoch 27, dev accuracy: 0.611\n",
            "Epoch 28, dev accuracy: 0.603\n",
            "Epoch 29, dev accuracy: 0.607\n",
            "Epoch 30, dev accuracy: 0.615\n",
            "Epoch 31, dev accuracy: 0.638\n",
            "11 > patience (10), stopping...\n",
            "\n",
            "Best Performing Model achieves dev accuracy of : 0.650\n",
            "Loaded model dev accuracy: 0.650\n",
            "\n",
            "Training model with d_model=64, num_encoder_layers=2, nhead=4\n",
            "0.494 is better than 0.000, saving model ...\n",
            "Epoch 0, dev accuracy: 0.494\n",
            "Epoch 1, dev accuracy: 0.494\n",
            "Epoch 2, dev accuracy: 0.494\n",
            "Epoch 3, dev accuracy: 0.494\n",
            "Epoch 4, dev accuracy: 0.494\n",
            "Epoch 5, dev accuracy: 0.494\n",
            "Epoch 6, dev accuracy: 0.494\n",
            "0.525 is better than 0.494, saving model ...\n",
            "Epoch 7, dev accuracy: 0.525\n",
            "0.584 is better than 0.525, saving model ...\n",
            "Epoch 8, dev accuracy: 0.584\n",
            "0.591 is better than 0.584, saving model ...\n",
            "Epoch 9, dev accuracy: 0.591\n",
            "0.607 is better than 0.591, saving model ...\n",
            "Epoch 10, dev accuracy: 0.607\n",
            "Epoch 11, dev accuracy: 0.580\n",
            "Epoch 12, dev accuracy: 0.607\n",
            "Epoch 13, dev accuracy: 0.588\n",
            "Epoch 14, dev accuracy: 0.591\n",
            "Epoch 15, dev accuracy: 0.607\n",
            "Epoch 16, dev accuracy: 0.599\n",
            "Epoch 17, dev accuracy: 0.603\n",
            "Epoch 18, dev accuracy: 0.607\n",
            "Epoch 19, dev accuracy: 0.556\n",
            "Epoch 20, dev accuracy: 0.564\n",
            "Epoch 21, dev accuracy: 0.576\n",
            "11 > patience (10), stopping...\n",
            "\n",
            "Best Performing Model achieves dev accuracy of : 0.607\n",
            "Loaded model dev accuracy: 0.607\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert results into a plot-friendly format\n",
        "d_models, num_layers, nheads, accuracies = zip(*results)\n",
        "\n",
        "for d_model, num_encoder_layers, nhead, accuracy in results:\n",
        "    print(f\"d_model={d_model}, num_encoder_layers={num_encoder_layers}, nhead={nhead}, accuracy={accuracy:.3f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BbaV11jFSiDS",
        "outputId": "15fda38c-7a40-409d-df22-62aec1d96fb7"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "d_model=16, num_encoder_layers=1, nhead=2, accuracy=0.700\n",
            "d_model=16, num_encoder_layers=1, nhead=4, accuracy=0.584\n",
            "d_model=16, num_encoder_layers=2, nhead=2, accuracy=0.661\n",
            "d_model=16, num_encoder_layers=2, nhead=4, accuracy=0.619\n",
            "d_model=64, num_encoder_layers=1, nhead=2, accuracy=0.654\n",
            "d_model=64, num_encoder_layers=1, nhead=4, accuracy=0.658\n",
            "d_model=64, num_encoder_layers=2, nhead=2, accuracy=0.650\n",
            "d_model=64, num_encoder_layers=2, nhead=4, accuracy=0.607\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6tSj2tAMI88r"
      },
      "source": [
        "**Q2**.  This transformer is forced to learn everything about the structure of language from the labeled dataset.  Word embeddings, however, already capture some of this structure, and can be incorporated into this model in an `nn.Embedding` layer.  Change the `TransformerClassifier` class above so that the `Embedding` layer uses pre-trained weights (do so with the `Embedding.from_pretrained` function described on the PyTorch [API](https://pytorch.org/docs/stable/generated/torch.nn.Embedding.html).  You can use any pre-trained embeddings you like, including the [GloVe vectors](https://raw.githubusercontent.com/dbamman/anlp24/main/data/glove.6B.50d.50K.txt) from class.  (Hint: doing so will require changes to `read_data` and `create_vocab_and_labels` since the word embeddings will give you your vocabulary.)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- The implemenation below use the GloVe vectors from class\n",
        "- Overwrite `TransformerClassifier` class and `read_data` and `create_vocab_and_labels` methods\n",
        "- Best Performing Model achieves dev accuracy of : `0.673`"
      ],
      "metadata": {
        "id": "_7qOwxExFBIT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from gensim.models import Word2Vec, KeyedVectors"
      ],
      "metadata": {
        "id": "gxldk4mO1Izd"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://raw.githubusercontent.com/dbamman/anlp24/main/data/glove.6B.50d.50K.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G6xOcQkz6N70",
        "outputId": "e5d989f8-6816-4924-cc0e-9dc772bf839f"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-10-13 03:57:10--  https://raw.githubusercontent.com/dbamman/anlp24/main/data/glove.6B.50d.50K.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.110.133, 185.199.111.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 21357798 (20M) [text/plain]\n",
            "Saving to: ‘glove.6B.50d.50K.txt.1’\n",
            "\n",
            "glove.6B.50d.50K.tx 100%[===================>]  20.37M  --.-KB/s    in 0.09s   \n",
            "\n",
            "2024-10-13 03:57:11 (224 MB/s) - ‘glove.6B.50d.50K.txt.1’ saved [21357798/21357798]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "glove_file = 'glove.6B.50d.50K.txt'\n",
        "\n",
        "glove_embeddings = KeyedVectors.load_word2vec_format(glove_file, binary=False)\n",
        "\n",
        "glove_embeddings"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VA5FywuG8d0Q",
        "outputId": "6a13db37-9dcf-4fe8-dfeb-9c8bcb629ea8"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<gensim.models.keyedvectors.KeyedVectors at 0x7ef6712c3760>"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class TransformerClassifier(nn.Module):\n",
        "    def __init__(self, num_labels, d_model, pretrained_embeddings, nhead=2, num_encoder_layers=1, dim_feedforward=256):\n",
        "\n",
        "        super(TransformerClassifier, self).__init__()\n",
        "\n",
        "        self.num_labels = num_labels\n",
        "        self.embedding = nn.Embedding.from_pretrained(pretrained_embeddings, freeze=False)\n",
        "        self.transformer = nn.Transformer(d_model=d_model, nhead=nhead, num_encoder_layers=num_encoder_layers, dim_feedforward=dim_feedforward, batch_first=True)\n",
        "        self.classifier = nn.Linear(d_model, self.num_labels)\n",
        "        self.pos_encoder = PositionalEncoding(d_model)\n",
        "\n",
        "    def forward(self, x, m):\n",
        "        if isinstance(x, list):\n",
        "            x = torch.tensor(x, dtype=torch.long)\n",
        "        if isinstance(m, list):\n",
        "            m = torch.tensor(m, dtype=torch.bool)\n",
        "\n",
        "        x = x.to(device)\n",
        "        m = m.to(device)\n",
        "\n",
        "        embed = self.embedding(x)\n",
        "        embed = self.pos_encoder(embed)\n",
        "        h = self.transformer.encoder(embed, src_key_padding_mask=m)\n",
        "        h = torch.mean(h, dim=1)\n",
        "        logits = self.classifier(h)\n",
        "\n",
        "        return logits\n",
        "\n",
        "def create_vocab_and_labels(filename, glove_embeddings):\n",
        "    glove_dim = glove_embeddings.vector_size\n",
        "\n",
        "    counts = Counter()\n",
        "    labels = {}\n",
        "    with open(filename, encoding=\"utf-8\") as file:\n",
        "        for line in file:\n",
        "            cols = line.rstrip().split(\"\\t\")\n",
        "            lab = cols[0]\n",
        "            text = word_tokenize(cols[1].lower())\n",
        "            for tok in text:\n",
        "                counts[tok] += 1\n",
        "\n",
        "            if lab not in labels:\n",
        "                labels[lab] = len(labels)\n",
        "\n",
        "    vocab = {\"[PAD]\": 0, \"[UNK]\": 1}\n",
        "    embeddings = [torch.zeros(glove_dim), torch.randn(glove_dim)]  # For [PAD] and [UNK]\n",
        "\n",
        "    for word in counts.keys():\n",
        "        if word in glove_embeddings:\n",
        "            vocab[word] = len(vocab)\n",
        "            embeddings.append(torch.tensor(glove_embeddings[word]))\n",
        "\n",
        "    embeddings = torch.stack(embeddings)\n",
        "\n",
        "    return vocab, labels, embeddings\n",
        "\n",
        "def read_data(filename, vocab, labels, max_length, max_docs=5000):\n",
        "    x = []\n",
        "    y = []\n",
        "    m = []\n",
        "\n",
        "    with open(filename, encoding=\"utf-8\") as file:\n",
        "        for idx, line in enumerate(file):\n",
        "            if idx >= max_docs:\n",
        "                break\n",
        "            cols = line.rstrip().split(\"\\t\")\n",
        "            lab = cols[0]\n",
        "            text = word_tokenize(cols[1].lower())\n",
        "            text_ids = []\n",
        "            for tok in text:\n",
        "                if tok in vocab:\n",
        "                    text_ids.append(vocab[tok])\n",
        "                else:\n",
        "                    text_ids.append(vocab[\"[UNK]\"])\n",
        "\n",
        "            text_ids = text_ids[:max_length]\n",
        "            mask = [0] * len(text_ids)\n",
        "\n",
        "            for i in range(len(text_ids), max_length):\n",
        "                text_ids.append(vocab[\"[PAD]\"])\n",
        "                mask.append(1)\n",
        "\n",
        "            x.append(text_ids)\n",
        "            m.append(mask)\n",
        "            y.append(labels[lab])\n",
        "\n",
        "    return x, y, m"
      ],
      "metadata": {
        "id": "HBav4ductLEc"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab, labels, embeddings = create_vocab_and_labels('train.tsv', glove_embeddings)\n",
        "train_x, train_y, train_m=read_data(\"train.tsv\", vocab, labels, max_length=max_length)\n",
        "dev_x, dev_y, dev_m=read_data(\"dev.tsv\", vocab, labels, max_length=max_length)"
      ],
      "metadata": {
        "id": "frTDpLOJyjpB"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classifier=TransformerClassifier(num_labels=len(labels), d_model=embeddings.size(1),\n",
        "                                 pretrained_embeddings=embeddings, dim_feedforward=1024)\n",
        "classifier=classifier.to(device)\n",
        "\n",
        "train_x_batch, train_y_match, train_m_match=get_batches(train_x, train_y, train_m, batch_size=batch_size)\n",
        "dev_x_batch, dev_y_match, dev_m_match=get_batches(dev_x, dev_y, dev_m, batch_size=batch_size)\n",
        "\n",
        "train(classifier, \"test_embedded.model\", train_x_batch, train_y_match, train_m_match, dev_x_batch, dev_y_match, dev_m_match)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TJPo1pRNymK7",
        "outputId": "b8499598-8d9b-4780-d29e-dff59c9ae8c7"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.494 is better than 0.000, saving model ...\n",
            "Epoch 0, dev accuracy: 0.494\n",
            "Epoch 1, dev accuracy: 0.494\n",
            "Epoch 2, dev accuracy: 0.494\n",
            "Epoch 3, dev accuracy: 0.494\n",
            "0.498 is better than 0.494, saving model ...\n",
            "Epoch 4, dev accuracy: 0.498\n",
            "0.572 is better than 0.498, saving model ...\n",
            "Epoch 5, dev accuracy: 0.572\n",
            "0.580 is better than 0.572, saving model ...\n",
            "Epoch 6, dev accuracy: 0.580\n",
            "0.607 is better than 0.580, saving model ...\n",
            "Epoch 7, dev accuracy: 0.607\n",
            "0.626 is better than 0.607, saving model ...\n",
            "Epoch 8, dev accuracy: 0.626\n",
            "Epoch 9, dev accuracy: 0.619\n",
            "0.638 is better than 0.626, saving model ...\n",
            "Epoch 10, dev accuracy: 0.638\n",
            "Epoch 11, dev accuracy: 0.619\n",
            "Epoch 12, dev accuracy: 0.603\n",
            "0.661 is better than 0.638, saving model ...\n",
            "Epoch 13, dev accuracy: 0.661\n",
            "Epoch 14, dev accuracy: 0.607\n",
            "Epoch 15, dev accuracy: 0.615\n",
            "0.673 is better than 0.661, saving model ...\n",
            "Epoch 16, dev accuracy: 0.673\n",
            "Epoch 17, dev accuracy: 0.669\n",
            "Epoch 18, dev accuracy: 0.642\n",
            "Epoch 19, dev accuracy: 0.658\n",
            "Epoch 20, dev accuracy: 0.626\n",
            "Epoch 21, dev accuracy: 0.669\n",
            "Epoch 22, dev accuracy: 0.642\n",
            "Epoch 23, dev accuracy: 0.615\n",
            "Epoch 24, dev accuracy: 0.638\n",
            "Epoch 25, dev accuracy: 0.658\n",
            "Epoch 26, dev accuracy: 0.650\n",
            "Epoch 27, dev accuracy: 0.650\n",
            "11 > patience (10), stopping...\n",
            "\n",
            "Best Performing Model achieves dev accuracy of : 0.673\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-12-4830a4bf0820>:50: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  model.load_state_dict(torch.load(model_filename))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "## To submit\n",
        "\n",
        "Congratulations on finishing this homework!\n",
        "Please follow the instructions below to download the notebook file (`.ipynb`) and its printed version (`.pdf`) for submission on bCourses -- remember **all cells must be executed**.\n",
        "\n",
        "1.  Download a copy of the notebook file: `File > Download > Download .ipynb`.\n",
        "\n",
        "2.  Print the notebook as PDF (via your browser, or tools like [nbconvert](https://nbconvert.readthedocs.io/en/latest/))."
      ],
      "metadata": {
        "id": "mpxBctVxKamS"
      }
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}